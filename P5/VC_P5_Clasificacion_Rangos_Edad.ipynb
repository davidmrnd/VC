{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c7c269",
   "metadata": {},
   "source": [
    "# Clasificación de Rangos de Edad con PCA + KNN y Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46429c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from FaceDetectors import FaceDetector\n",
    "from FaceNormalizationUtils import Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_range(age):\n",
    "    age = int(age)\n",
    "    if age <= 12:\n",
    "        return \"Niño\"\n",
    "    elif age <= 19:\n",
    "        return \"Adolescente\"\n",
    "    elif age <= 35:\n",
    "        return \"Joven\"\n",
    "    elif age <= 60:\n",
    "        return \"Adulto\"\n",
    "    else:\n",
    "        return \"Anciano\"\n",
    "\n",
    "def load_age_dataset_ranged(base_path, img_size=(100,100)):\n",
    "    X, y = [], []\n",
    "    folders = sorted([f for f in os.listdir(base_path) if f.isdigit()], key=lambda x: int(x))\n",
    "    for folder in folders:\n",
    "        age = int(folder)\n",
    "        age_range = age_to_range(age)\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        for fname in os.listdir(folder_path):\n",
    "            path = os.path.join(folder_path, fname)\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.resize(img, img_size)\n",
    "            X.append(img.flatten())\n",
    "            y.append(age_range)\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a59335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pca(X, num_components=100):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    Xc = X - mean\n",
    "    cov = np.cov(Xc.T)\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvecs = eigvecs[:, idx[:num_components]]\n",
    "    return eigvecs, mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c41da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_kfold(X_pca, y, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    accs = []\n",
    "    for tr, te in kf.split(X_pca):\n",
    "        Xtr, Xte = X_pca[tr], X_pca[te]\n",
    "        ytr, yte = y[tr], y[te]\n",
    "        clf = KNeighborsClassifier(n_neighbors=5)\n",
    "        clf.fit(Xtr, ytr)\n",
    "        pred = clf.predict(Xte)\n",
    "        accs.append(accuracy_score(yte, pred))\n",
    "    return accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ace00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (9778, 10000) (9778,)\n",
      "Accuracy medio: 0.5109432057699046\n",
      "Modelo final entrenado.\n"
     ]
    }
   ],
   "source": [
    "# Ruta del dataset (MODIFICA ESTA)\n",
    "dataset_path = \"Dataset\"\n",
    "\n",
    "X, y = load_age_dataset_ranged(dataset_path)\n",
    "print(\"Dataset:\", X.shape, y.shape)\n",
    "\n",
    "W, mean = compute_pca(X, num_components=100)\n",
    "X_pca = (X - mean) @ W\n",
    "\n",
    "accs = run_kfold(X_pca, y)\n",
    "print(\"Accuracy medio:\", np.mean(accs))\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=7)\n",
    "clf.fit(X_pca, y)\n",
    "\n",
    "print(\"Modelo final entrenado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e729ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_webcam_frame(frame, img_size=(100,100)):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, img_size)\n",
    "    return gray.flatten()\n",
    "\n",
    "def predict_age_range(img_flat, W, mean, clf):\n",
    "    img_pca = (img_flat - mean) @ W\n",
    "    return clf.predict([img_pca])[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e741a1eb",
   "metadata": {},
   "source": [
    "# Discriminante por edades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "745c69fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presiona 'q' para salir.\n"
     ]
    }
   ],
   "source": [
    "detector = FaceDetector()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"Presiona 'q' para salir.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convertir a RGB porque MTCNN usa imágenes RGB\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detectar la cara más grande\n",
    "    values = detector.SingleFaceEyesDetection(rgb, facedet='MTCNN', eyesdet='')\n",
    "    \n",
    "    if values is not None:\n",
    "        (x, y, w, h), eyes, shape = values\n",
    "        \n",
    "        # Recortar la cara detectada\n",
    "        face_crop = rgb[y:y+h, x:x+w]\n",
    "\n",
    "        # Preprocesar la cara para PCA\n",
    "        try:\n",
    "            face_gray = cv2.cvtColor(face_crop, cv2.COLOR_RGB2GRAY)\n",
    "            face_gray = cv2.resize(face_gray, (100,100))\n",
    "            face_flat = face_gray.flatten()\n",
    "\n",
    "            # Proyectar en PCA y predecir\n",
    "            pred_range = predict_age_range(face_flat, W, mean, clf)\n",
    "\n",
    "            if pred_range == \"Niño\":\n",
    "                color = (255, 0, 0)\n",
    "            elif pred_range == \"Adolescente\":\n",
    "                color = (0, 255, 255)\n",
    "            elif pred_range == \"Joven\":\n",
    "                color = (0, 255, 0)\n",
    "            elif pred_range == \"Adulto\":\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                color = (128, 0, 128)\n",
    "\n",
    "\n",
    "            # Mostrar recuadro de detección\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "\n",
    "            # Mostrar texto\n",
    "            cv2.putText(frame, f\"Rango: {pred_range}\", (x, y-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, color , 2)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    cv2.imshow(\"Clasificador Edad\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bcc3db",
   "metadata": {},
   "source": [
    "# Filtro por edades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f52dc09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Cargar PNGs con canal alfa\n",
    "# -------------------------------------------------------------\n",
    "def load_png(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"No se encontró {path}\")\n",
    "    return img\n",
    "\n",
    "try:\n",
    "    png_chupete = load_png(\"assets/chupete.png\")\n",
    "    png_gafas   = load_png(\"assets/gafas.png\")\n",
    "    png_gorra   = load_png(\"assets/gorra.png\")\n",
    "    png_baston  = load_png(\"assets/baston.png\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error cargando recursos: {e}. Asegúrate de que la carpeta 'assets' exista.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "850b6406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Función de overlay con alfa \n",
    "# -------------------------------------------------------------\n",
    "def overlay_alpha(frame, overlay, x, y):\n",
    "    h, w = overlay.shape[:2]\n",
    "    h_frame, w_frame = frame.shape[:2]\n",
    "\n",
    "    # Coordenadas de recorte para el frame\n",
    "    x1, y1 = max(0, x), max(0, y)\n",
    "    x2, y2 = min(w_frame, x + w), min(h_frame, y + h)\n",
    "\n",
    "    # Coordenadas de recorte para el overlay\n",
    "    ox1 = x1 - x\n",
    "    oy1 = y1 - y\n",
    "    ox2 = w - (x + w - x2)\n",
    "    oy2 = h - (y + h - y2)\n",
    "    \n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return frame\n",
    "\n",
    "    # Extraer ROIs\n",
    "    roi_frame = frame[y1:y2, x1:x2]\n",
    "    roi_overlay = overlay[oy1:oy2, ox1:ox2]\n",
    "\n",
    "    alpha = roi_overlay[:,:,3] / 255.0\n",
    "    \n",
    "    if roi_frame.shape[:2] != alpha.shape[:2]:\n",
    "         return frame \n",
    "\n",
    "    # Alpha blending\n",
    "    for c in range(3):\n",
    "        roi_frame[:,:,c] = (roi_frame[:,:,c] * (1 - alpha) + \n",
    "                            roi_overlay[:,:,c] * alpha).astype(np.uint8)\n",
    "        \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9223214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. INICIANDO CÁMARA (Clasificador Edad + Accesorios) ---\n",
      "Presiona 'q' para salir.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Detector y normalizador\n",
    "# -------------------------------------------------------------\n",
    "detector = FaceDetector()\n",
    "norm = Normalization()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"\\n--- 2. INICIANDO CÁMARA (Clasificador Edad + Accesorios) ---\")\n",
    "print(\"Presiona 'q' para salir.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    values = detector.SingleFaceEyesDetection(rgb, facedet='MTCNN', eyesdet='')\n",
    "\n",
    "    if values is not None:\n",
    "        (x, y, w, h), eyes, shape = values\n",
    "\n",
    "        # ------------------------------\n",
    "        # Extraer ojos de forma segura (lx, ly, rx, ry)\n",
    "        # ------------------------------\n",
    "        lx = ly = rx = ry = None\n",
    "        if isinstance(eyes, dict):\n",
    "            lx, ly = eyes[\"left\"]\n",
    "            rx, ry = eyes[\"right\"]\n",
    "        elif isinstance(eyes, (list, tuple)):\n",
    "            if len(eyes) == 4:\n",
    "                lx, ly, rx, ry = eyes\n",
    "            elif len(eyes) >= 2 and isinstance(eyes[0], (list, tuple)):\n",
    "                lx, ly = eyes[0]\n",
    "                rx, ry = eyes[1]\n",
    "\n",
    "        if None in (lx, ly, rx, ry):\n",
    "            continue\n",
    "\n",
    "        # ------------------------------\n",
    "        # Normalizar para dist_eyes y angle\n",
    "        # ------------------------------\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        try:\n",
    "            norm.normalize_gray_img(gray, lx, ly, rx, ry, kind=\"FACE\")\n",
    "            dist_eyes = norm.distf_eyes\n",
    "            angle = norm.anglef_eyes\n",
    "        except AttributeError:\n",
    "            # Fallback: calcular ángulo/distancia directamente\n",
    "            dx = rx - lx\n",
    "            dy = ry - ly\n",
    "            angle = np.degrees(np.arctan2(dy, dx))\n",
    "            dist_eyes = np.sqrt(dx*dx + dy*dy)\n",
    "\n",
    "        # ------------------------------\n",
    "        # Predicción de rango de edad\n",
    "        # ------------------------------\n",
    "        if W is not None and mean is not None and clf is not None:\n",
    "            try:\n",
    "                face_crop = cv2.cvtColor(rgb[y:y+h, x:x+w], cv2.COLOR_RGB2GRAY)\n",
    "                crop_gray = cv2.resize(face_crop, (100,100))\n",
    "                pred_range = predict_age_range(crop_gray.flatten(), W, mean, clf)\n",
    "            except Exception as e:\n",
    "                pred_range = \"Adulto\"\n",
    "        else:\n",
    "            pred_range = \"Adulto\"\n",
    "\n",
    "        # ------------------------------\n",
    "        # Seleccionar accesorio y posición (CORRECCIÓN DE POSICIÓN)\n",
    "        # ------------------------------\n",
    "        if pred_range == \"Niño\":\n",
    "            png = png_chupete\n",
    "            pos_norm = (35, 75)  # boca \n",
    "            size_norm = 20\n",
    "        elif pred_range == \"Adolescente\":\n",
    "            png = png_gafas\n",
    "            pos_norm = (30, 43)  # ojos\n",
    "            size_norm = 30\n",
    "        elif pred_range == \"Joven\":\n",
    "            png = png_gorra\n",
    "            pos_norm = (20, 5)   # frente\n",
    "            size_norm = 50\n",
    "        else:\n",
    "            png = png_baston\n",
    "            pos_norm = (5, 60)   # lateral\n",
    "            size_norm = 25\n",
    "\n",
    "        # ------------------------------\n",
    "        # Transformar el PNG (Coordenadas Normalizadas -> Originales)\n",
    "        # -------------------------------------------------------------\n",
    "        \n",
    "        cx_o = (lx + rx) // 2\n",
    "        cy_o = (ly + ry) // 2\n",
    "\n",
    "        # Distancia estándar (asumiendo 26px entre ojos en el espacio 100x100)\n",
    "        dist_std = 26 \n",
    "        scale = dist_eyes / dist_std\n",
    "\n",
    "        # Convertir posición normalizada a desplazamiento original (dx, dy)\n",
    "        dx = (pos_norm[0] - 30) * scale # 30: centro x de referencia\n",
    "        dy = (pos_norm[1] - 37) * scale # 37: centro y de referencia (entre ojos)\n",
    "        cx = int(cx_o + dx)\n",
    "        cy = int(cy_o + dy)\n",
    "\n",
    "        # Redimensionar y Rotar PNG\n",
    "        oh, ow = png.shape[:2]\n",
    "        new_w = int(size_norm * scale * 2)\n",
    "        scale_png = new_w / ow\n",
    "        new_h = int(oh * scale_png)\n",
    "        \n",
    "        if new_w <= 0 or new_h <= 0:\n",
    "            continue \n",
    "\n",
    "        png_scaled = cv2.resize(png, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Rotar \n",
    "        bgr = png_scaled[:,:,:3]\n",
    "        alpha = png_scaled[:,:,3]\n",
    "        M = cv2.getRotationMatrix2D((new_w//2, new_h//2), -angle, 1.0)\n",
    "        bgr_rot = cv2.warpAffine(bgr, M, (new_w, new_h), borderMode=cv2.BORDER_TRANSPARENT)\n",
    "        alpha_rot = cv2.warpAffine(alpha, M, (new_w, new_h), borderMode=cv2.BORDER_TRANSPARENT)\n",
    "        png_rot = np.dstack([bgr_rot, alpha_rot])\n",
    "\n",
    "        # Coordenadas superior izquierda (para overlay)\n",
    "        x1 = cx - new_w // 2\n",
    "        y1 = cy - new_h // 2\n",
    "\n",
    "        # Superponer PNG\n",
    "        frame = overlay_alpha(frame, png_rot, x1, y1)\n",
    "\n",
    "    cv2.imshow(\"Edad + Accesorios\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
